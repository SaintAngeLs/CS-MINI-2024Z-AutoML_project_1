{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definicja Problemu\n",
    "\n",
    "Niech:\n",
    "\n",
    "- $ X \\in \\mathbb{R}^{n \\times d} $ — macierz danych wejściowych, gdzie $ n $ to liczba próbek, a $ d $ to liczba cech.\n",
    "- $ y \\in \\mathbb{R}^n $ — wektor etykiet (lub wartości ciągłych w przypadku regresji).\n",
    "- $ f_{\\theta}(X) $ — model predykcyjny parametryzowany przez wektor hiperparametrów $ \\theta $.\n",
    "\n",
    "Naszym celem jest znalezienie optymalnych hiperparametrów $ \\theta^* $, które minimalizują funkcję kosztu $ \\mathcal{L}(X, y, \\theta) $, wyrażoną jako:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg \\min_{\\theta} \\mathcal{L}(X, y, \\theta)\n",
    "$$\n",
    "\n",
    "Funkcja kosztu zależy od rodzaju problemu (klasyfikacja/regresja) i wybranego modelu. Przykładowe funkcje kosztu to:\n",
    "\n",
    "- Dla regresji:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(X, y, \\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - f_{\\theta}(X_i) \\right)^2\n",
    "$$\n",
    "\n",
    "- Dla klasyfikacji (np. log-loss dla regresji logistycznej):\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(X, y, \\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\hat{y}_i + (1 - y_i) \\log (1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "### 2. Metody Optymalizacji Hiperparametrów\n",
    "\n",
    "W kodzie zastosowano trzy różne metody optymalizacji hiperparametrów: wyszukiwanie siatką (Grid Search), wyszukiwanie losowe (Random Search) oraz optymalizacja bayesowska (Bayesian Optimization).\n",
    "\n",
    "#### 2.1 Wyszukiwanie Siatką (Grid Search)\n",
    "\n",
    "Grid Search polega na przeszukaniu skończonego zbioru możliwych wartości hiperparametrów $ \\theta $ z siatki $ \\Theta $, tak aby znaleźć optymalne ustawienia:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg \\min_{\\theta \\in \\Theta} \\mathcal{L}(X, y, \\theta)\n",
    "$$\n",
    "\n",
    "Macierz parametrów $ \\Theta $ może wyglądać następująco:\n",
    "\n",
    "$$\n",
    "\\Theta = \\{ (\\theta_1, \\theta_2, \\ldots, \\theta_k) \\mid \\theta_i \\in \\{ \\theta_i^1, \\theta_i^2, \\ldots, \\theta_i^m \\} \\}\n",
    "$$\n",
    "\n",
    "Jest to metoda wyczerpująca, ponieważ testowane są wszystkie możliwe kombinacje parametrów.\n",
    "\n",
    "#### 2.2 Wyszukiwanie Losowe (Random Search)\n",
    "\n",
    "W wyszukiwaniu losowym parametry $ \\theta $ są wybierane losowo z rozkładów prawdopodobieństwa przypisanych każdemu parametrowi:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg \\min_{\\theta \\sim P(\\Theta)} \\mathcal{L}(X, y, \\theta)\n",
    "$$\n",
    "\n",
    "gdzie $ P(\\Theta) $ to rozkład losowy na przestrzeni parametrów $ \\Theta $.\n",
    "\n",
    "Zaletą tego podejścia jest możliwość zbadania większej przestrzeni parametrów w krótszym czasie, chociaż nie gwarantuje ono znalezienia najlepszego rozwiązania.\n",
    "\n",
    "#### 2.3 Optymalizacja Bayesowska\n",
    "\n",
    "Optymalizacja bayesowska traktuje funkcję kosztu jako funkcję losową, którą modeluje się za pomocą procesu Gaussa (Gaussian Process). Celem jest znalezienie optymalnego zestawu parametrów przez maksymalizację funkcji nabywania $ a(\\theta) $, która równoważy eksplorację i eksploatację:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg \\max_{\\theta} a(\\theta)\n",
    "$$\n",
    "\n",
    "Funkcja nabywania określa, jak prawdopodobne jest, że dany zestaw parametrów poprawi obecne najlepsze rozwiązanie.\n",
    "\n",
    "### 3. Modele Uczenia Maszynowego\n",
    "\n",
    "Zastosowane w kodzie modele to:\n",
    "\n",
    "- **Random Forest** — las losowy (klasyfikator):\n",
    "\n",
    "  $$\n",
    "  f_{\\text{RF}}(X) = \\frac{1}{T} \\sum_{t=1}^{T} h_t(X)\n",
    "  $$\n",
    "\n",
    "  gdzie $ h_t(X) $ to pojedyncze drzewo decyzyjne, a $ T $ to liczba drzew.\n",
    "\n",
    "- **XGBoost** — gradient boosting:\n",
    "\n",
    "  $$\n",
    "  f_{\\text{XGB}}(X) = \\sum_{t=1}^{T} \\gamma_t h_t(X)\n",
    "  $$\n",
    "\n",
    "  gdzie $ \\gamma_t $ to waga przypisana każdemu drzewu.\n",
    "\n",
    "- **Elastic Net** — regresja liniowa z regularizacją:\n",
    "\n",
    "  $$\n",
    "  \\mathcal{L}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\theta^T X_i \\right)^2 + \\alpha \\left( \\lambda_1 \\|\\theta\\|_1 + \\lambda_2 \\|\\theta\\|_2^2 \\right)\n",
    "  $$\n",
    "\n",
    "  Gdzie $ \\lambda_1 $ kontroluje regularizację $ L1 $ (Lasso), a $ \\lambda_2 $ kontroluje regularizację $ L2 $ (Ridge).\n",
    "\n",
    "### 4. Przetwarzanie Wyników\n",
    "\n",
    "Wyniki z każdej z metod optymalizacji są rejestrowane i porównywane. Dla każdej iteracji, uzyskiwane są wyniki $ \\text{score}_{\\text{grid}}, \\text{score}_{\\text{random}}, \\text{score}_{\\text{bayes}} $. Wyniki te są następnie używane do stworzenia porównawczych wykresów.\n",
    "\n",
    "- **Wynik Grid Search** dla iteracji $ t $:\n",
    "\n",
    "  $$\n",
    "  \\text{score}_{\\text{grid}}^{(t)} = \\mathcal{L}(X, y, \\theta_{\\text{grid}}^{(t)})\n",
    "  $$\n",
    "\n",
    "- **Wynik Random Search** dla iteracji $ t $:\n",
    "\n",
    "  $$\n",
    "  \\text{score}_{\\text{random}}^{(t)} = \\mathcal{L}(X, y, \\theta_{\\text{random}}^{(t)})\n",
    "  $$\n",
    "\n",
    "- **Wynik Bayesian Optimization** dla iteracji $ t $:\n",
    "\n",
    "  $$\n",
    "  \\text{score}_{\\text{bayes}}^{(t)} = \\mathcal{L}(X, y, \\theta_{\\text{bayes}}^{(t)})\n",
    "  $$\n",
    "\n",
    "Na koniec wybierany jest najlepszy wynik dla każdej metody.\n",
    "\n",
    "### 5. Podsumowanie Wyników\n",
    "\n",
    "Dla każdej z metod uzyskiwane są najlepsze wartości funkcji kosztu:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{best}} = \\arg \\min_{\\theta} \\mathcal{L}(X, y, \\theta)\n",
    "$$\n",
    "\n",
    "Porównanie trzech metod (Grid Search, Random Search, Bayesian Optimization) można przedstawić graficznie na wykresach, które pokazują, jak zmieniają się wyniki wraz z iteracjami optymalizacji.\n",
    "\n",
    "Powyższy opis formalnie prezentuje matematyczne podstawy operacji na wektorach, macierzach i funkcjach kosztu, używanych do optymalizacji hiperparametrów modeli uczenia maszynowego.\n",
    "\n",
    "### 6. Analiza Statystyczna i Test ANOVA\n",
    "\n",
    "Aby sprawdzić, czy różnice między wynikami różnych metod są statystycznie istotne, używamy analizy wariancji (ANOVA). Załóżmy, że dla trzech metod optymalizacji $ \\text{Grid Search}, \\text{Random Search}, \\text{Bayesian Optimization} $, uzyskaliśmy odpowiednie wyniki $ \\text{score}_{\\text{grid}}, \\text{score}_{\\text{random}}, \\text{score}_{\\text{bayes}} $.\n",
    "\n",
    "Test ANOVA porównuje te wyniki:\n",
    "\n",
    "$$\n",
    "H_0: \\mu_{\\text{grid}} = \\mu_{\\text{random}} = \\mu_{\\text{bayes}}\n",
    "$$\n",
    "\n",
    "Jeśli wartość p $ p \\text{-value} < 0.05 $, odrzucamy hipotezę zerową i uznajemy, że różnice między wynikami są statystycznie istotne. W przeciwnym razie nie ma istotnych różnic między metodami.\n",
    "\n",
    "### 7. Wykresy i Wizualizacja Wyników\n",
    "\n",
    "Na podstawie uzyskanych wyników z każdej metody, możemy stworzyć wykresy porównawcze, które pokazują, jak każda metoda radziła sobie na przestrzeni iteracji. Na przykład, poniższy wykres przedstawia porównanie wyników Grid Search i Bayesian Optimization na jednym ze zbiorów danych:\n",
    "\n",
    "![Przykładowy Wykres](../results/breast_cancer_xgboost_tuning_results.png)\n",
    "\n",
    "### 8. Wnioski\n",
    "\n",
    "- Z analizy wynika, że optymalizacja bayesowska skuteczniej znajduje lepsze wartości hiperparametrów w krótszym czasie niż Grid Search.\n",
    "- W przypadku większych zbiorów danych i bardziej złożonych modeli, Bayesian Optimization przynosi znaczące korzyści.\n",
    "- Analiza statystyczna (ANOVA) wykazała istotne różnice w wynikach dla metod optymalizacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
